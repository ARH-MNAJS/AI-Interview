"use strict";exports.id=501,exports.ids=[501],exports.modules={8501:(e,t,r)=>{r.d(t,{Ce:()=>u,Hc:()=>h,IV:()=>f,OY:()=>p,Th:()=>c,W9:()=>m,a1:()=>l,iI:()=>d,uP:()=>i,zX:()=>g});var a=r(6780);r(7704);var n=r(7920),o=r(7870),s=r(2348);async function l(e){let{interviewId:t,userId:r,transcript:a,feedbackId:l}=e;try{let e,i;let c=a.map(e=>`- ${e.role}: ${e.content}
`).join("");s.v.info("CreateFeedback","Starting feedback generation",{interviewId:t,userId:r,transcriptLength:c.length});let d=`You are an AI interviewer analyzing a mock interview. Your task is to evaluate the candidate based on structured categories. Be thorough and detailed in your analysis. Don't be lenient with the candidate. If there are mistakes or areas for improvement, point them out.

Transcript:
${c}

Please analyze this interview and provide feedback in the following JSON format. IMPORTANT: Use only simple text in comments without special characters, quotes, or line breaks:

{
  "totalScore": <number 0-100>,
  "categoryScores": [
    {
      "name": "Communication Skills",
      "score": <number 0-100>,
      "comment": "detailed comment about clarity and articulation"
    },
    {
      "name": "Technical Knowledge", 
      "score": <number 0-100>,
      "comment": "detailed comment about understanding of key concepts"
    },
    {
      "name": "Problem Solving",
      "score": <number 0-100>, 
      "comment": "detailed comment about ability to analyze problems and propose solutions"
    },
    {
      "name": "Cultural Fit",
      "score": <number 0-100>,
      "comment": "detailed comment about alignment with company values and job role"
    },
    {
      "name": "Confidence and Clarity",
      "score": <number 0-100>,
      "comment": "detailed comment about confidence in responses and engagement"
    }
  ],
  "strengths": ["strength 1", "strength 2", "strength 3"],
  "areasForImprovement": ["area 1", "area 2", "area 3"],
  "finalAssessment": "overall assessment paragraph"
}

CRITICAL: Return only valid JSON with no markdown code blocks, no additional text, and no special characters in strings. Avoid apostrophes, quotes within strings, and newlines.`,g=await o.d.generateResponse([{role:"user",content:d}]);s.v.debug("CreateFeedback","Raw LLM response",{response:g});let m=g.trim();m.startsWith("```json")?m=m.replace(/^```json\s*/,"").replace(/\s*```$/,""):m.startsWith("```")&&(m=m.replace(/^```\s*/,"").replace(/\s*```$/,"")),m=m.replace(/[\u0000-\u001F\u007F-\u009F]/g,"").replace(/\r\n/g," ").replace(/\n/g," ").replace(/\r/g," ").replace(/\t/g," ").replace(/\s+/g," ").trim();try{e=JSON.parse(m)}catch(t){s.v.error("CreateFeedback","Failed to parse JSON response",{error:t,originalResponse:g.slice(0,500),cleanedResponse:m.slice(0,500)});try{let t=m.match(/\{[\s\S]*\}/);if(t){let r=t[0];r=r.replace(/\\n/g," ").replace(/\\r/g,"").replace(/\\t/g," ").replace(/\s+/g," ").trim(),e=JSON.parse(r),s.v.info("CreateFeedback","Successfully parsed JSON after aggressive cleaning")}else throw Error("No JSON object found in response")}catch(t){s.v.error("CreateFeedback","Second parsing attempt failed",{error:t,response:g.slice(0,1e3)}),e={totalScore:75,categoryScores:[{name:"Communication Skills",score:75,comment:"Analysis pending - JSON parse error"},{name:"Technical Knowledge",score:75,comment:"Analysis pending - JSON parse error"},{name:"Problem Solving",score:75,comment:"Analysis pending - JSON parse error"},{name:"Cultural Fit",score:75,comment:"Analysis pending - JSON parse error"},{name:"Confidence and Clarity",score:75,comment:"Analysis pending - JSON parse error"}],strengths:["Interview completed successfully"],areasForImprovement:["Feedback generation needs improvement"],finalAssessment:"Feedback generation encountered technical issues. Please review transcript manually."}}}let u={interviewId:t,userId:r,totalScore:e.totalScore,categoryScores:e.categoryScores,strengths:e.strengths,areasForImprovement:e.areasForImprovement,finalAssessment:e.finalAssessment,createdAt:new Date().toISOString()};return i=l?n.db.collection("feedback").doc(l):n.db.collection("feedback").doc(),await i.set(u),{success:!0,feedbackId:i.id}}catch(e){return console.error("Error saving feedback:",e),{success:!1}}}async function i(e){return(await n.db.collection("interviews").doc(e).get()).data()}async function c(e){let{interviewId:t,userId:r}=e,a=await n.db.collection("feedback").where("interviewId","==",t).where("userId","==",r).limit(1).get();if(a.empty)return null;let o=a.docs[0];return{id:o.id,...o.data()}}async function d(e){try{let t=await n.db.collection("feedback").doc(e).get();if(!t.exists)return null;return{id:t.id,...t.data()}}catch(e){return console.error("Error fetching feedback by ID:",e),null}}async function g(e){try{let t=await n.db.collection("users").doc(e).get();if(!t.exists)return[];let r=t.data();if(!r.college||!r.branch||!r.year)return f({userId:e});return(await n.db.collection("interviews").where("finalized","==",!0).where("userId","!=",e).orderBy("createdAt","desc").get()).docs.filter(e=>{let t=e.data();if(!t.targetColleges||!t.targetBranches||!t.targetYears)return!0;let a=t.targetColleges.includes(r.college),n=t.targetBranches.includes(r.branch),o=t.targetYears.includes(parseInt(r.year));return a&&n&&o}).map(e=>({id:e.id,...e.data()}))}catch(e){return console.error("Error fetching interviews for student:",e),[]}}async function m(e,t){try{console.log("\uD83D\uDD0D getInterviewsWithFilters called with:",{filters:e,userId:t}),console.error("DEBUG: getInterviewsWithFilters called with filters:",JSON.stringify(e));let r=n.db.collection("interviews").where("finalized","==",!0);t&&(r=r.where("userId","!=",t),console.log("\uD83D\uDC64 Excluding interviews from user:",t)),console.log("\uD83D\uDCE1 Executing database query...");let a=await r.orderBy("createdAt","desc").get();if(console.log("\uD83D\uDCCA Total interviews from DB:",a.docs.length),console.error("DEBUG: Total interviews from DB:",a.docs.length),a.docs.length>0){let e=a.docs[0].data();console.log("\uD83D\uDCDD Sample interview structure:",{id:a.docs[0].id,targetColleges:e.targetColleges,targetBranches:e.targetBranches,targetYears:e.targetYears,role:e.role,type:e.type})}let o=a.docs.filter(t=>{let r=t.data();if(console.log(`ðŸ” Checking interview ${t.id}:`,{targetColleges:r.targetColleges,targetBranches:r.targetBranches,targetYears:r.targetYears}),e.college&&r.targetColleges){let t=r.targetColleges.includes(e.college);if(console.log(`  College filter (${e.college}):`,t),!t)return!1}if(e.branch&&r.targetBranches){let t=r.targetBranches.includes(e.branch);if(console.log(`  Branch filter (${e.branch}):`,t),!t)return!1}if(e.year&&r.targetYears){let t=parseInt(e.year),a=r.targetYears.includes(t);if(console.log(`  Year filter (${e.year} -> ${t}):`,a,"in",r.targetYears),!a)return!1}return console.log(`  âœ… Interview ${t.id} matches all filters`),!0});return console.log("\uD83C\uDFAF Filtered interviews count:",o.length),console.error("DEBUG: Final filtered count:",o.length),o.map(e=>({id:e.id,...e.data()}))}catch(e){return console.error("\uD83D\uDCA5 Error fetching interviews with filters:",e),[]}}async function u(e){try{console.log("\uD83D\uDD0D [getInterviewAttempts] Starting with interviewId:",e);let t=await n.db.collection("feedback").where("interviewId","==",e).orderBy("createdAt","desc").get();console.log("\uD83D\uDCCA [getInterviewAttempts] Raw feedback from DB:",{interviewId:e,feedbackCount:t.docs.length,feedbacks:t.docs.map(e=>({id:e.id,userId:e.data().userId,totalScore:e.data().totalScore,createdAt:e.data().createdAt}))});let r=[];for(let e of t.docs){let t=e.data();console.log(`ðŸ” [getInterviewAttempts] Processing feedback ${e.id} for user:`,t.userId);let a=await n.db.collection("users").doc(t.userId).get();if(a.exists){let n=a.data();console.log(`âœ… [getInterviewAttempts] Found user data for ${t.userId}:`,{name:n.name,email:n.email,college:n.college,branch:n.branch,year:n.year}),r.push({feedbackId:e.id,studentName:n.name,studentEmail:n.email,totalScore:t.totalScore,attemptDate:t.createdAt,college:n.college||"N/A",branch:n.branch||"N/A",year:n.year||"N/A"})}else console.warn(`âŒ [getInterviewAttempts] User document not found for userId:`,t.userId)}return console.log("\uD83C\uDFAF [getInterviewAttempts] Final attempts result:",{interviewId:e,attemptCount:r.length,attempts:r.map(e=>({feedbackId:e.feedbackId,studentName:e.studentName,college:e.college,totalScore:e.totalScore}))}),r}catch(e){return console.error("âŒ [getInterviewAttempts] Error fetching interview attempts:",e),[]}}async function h(e){try{let{collegeId:t,branch:r,year:a}=e;console.log("\uD83D\uDD0D [getInterviewsForTPO] Starting with params:",{collegeId:t,branch:r,year:a});let o=n.db.collection("interviews").where("finalized","==",!0).where("targetColleges","array-contains",t);console.log("\uD83D\uDCE1 [getInterviewsForTPO] Executing Firestore query with targetColleges array-contains:",t);let s=await o.orderBy("createdAt","desc").get();console.log("\uD83D\uDCCA [getInterviewsForTPO] Raw interviews from DB:",{count:s.docs.length,collegeId:t,interviews:s.docs.map(e=>{let t=e.data();return{id:e.id,role:t.role,targetColleges:t.targetColleges,targetBranches:t.targetBranches,targetYears:t.targetYears,createdAt:t.createdAt}})});let l=s.docs.filter(e=>{let t=e.data();return(console.log(`ðŸ” [getInterviewsForTPO] Filtering interview ${e.id}:`,{targetBranches:t.targetBranches,targetYears:t.targetYears,filterBranch:r,filterYear:a}),r&&t.targetBranches&&!t.targetBranches.includes(r))?(console.log(`âŒ [getInterviewsForTPO] Interview ${e.id} excluded by branch filter`),!1):a&&t.targetYears&&!t.targetYears.includes(parseInt(a))?(console.log(`âŒ [getInterviewsForTPO] Interview ${e.id} excluded by year filter`),!1):(console.log(`âœ… [getInterviewsForTPO] Interview ${e.id} passed all filters`),!0)});console.log("\uD83C\uDFAF [getInterviewsForTPO] Final filtered result:",{originalCount:s.docs.length,filteredCount:l.length,collegeId:t,branch:r,year:a});let i=l.map(e=>({id:e.id,...e.data()}));return console.log("\uD83D\uDCE4 [getInterviewsForTPO] Returning interviews:",i.length),i}catch(e){return console.error("âŒ [getInterviewsForTPO] Error fetching interviews for TPO:",e),e&&"object"==typeof e&&"code"in e&&(9===e.code||e.message?.includes("index"))&&(console.error("\uD83D\uDEA8 [getInterviewsForTPO] COMPOSITE INDEX ERROR - You need to create a Firestore composite index!"),console.error("\uD83D\uDD17 Index needed for: finalized (==) + targetColleges (array-contains) + createdAt (desc)"),console.error("\uD83D\uDCDD Go to Firebase Console > Firestore > Indexes to create it")),[]}}async function f(e){let{userId:t,limit:r=20}=e;return(await n.db.collection("interviews").orderBy("createdAt","desc").where("finalized","==",!0).where("userId","!=",t).limit(r).get()).docs.map(e=>({id:e.id,...e.data()}))}async function p(e){return(await n.db.collection("interviews").where("userId","==",e).orderBy("createdAt","desc").get()).docs.map(e=>({id:e.id,...e.data()}))}(0,r(960).D)([l,i,c,d,g,m,u,h,f,p]),(0,a.A)(l,"4080e8cde92d64d0ca432dfdd1ab765f756e9d9439",null),(0,a.A)(i,"40a5ae7fe9ce7e59a3d6cc294b10383696b4519a49",null),(0,a.A)(c,"40c1dd97a55e725d42affbac1172bc1c9b2a7a00fd",null),(0,a.A)(d,"4047032653a9928632cb9f39d640b8bb6af14f2c77",null),(0,a.A)(g,"40cb38bc229f416c427f8b0c2f0a413e1dde0902d6",null),(0,a.A)(m,"6091a61179fe7d2980e5d9dcf6c42cf1bf7a48fe63",null),(0,a.A)(u,"40ad97c5c57471817a56b383d5cefeeca547ff595a",null),(0,a.A)(h,"40317cc706bde30e3f306e8f198075a413378b33ff",null),(0,a.A)(f,"406bad0a6970c7ffc51885c00fcc2229d1f30b2718",null),(0,a.A)(p,"40ad0a852413f786204b5bce3a329a487a5d02b15b",null)},9429:(e,t,r)=>{r.d(t,{E$:()=>a});let a={EDGE_TTS:{URL:process.env.NEXT_PUBLIC_EDGE_TTS_URL||"https://dyptts.ccxai.uk",VOICE_ID:process.env.NEXT_PUBLIC_TTS_VOICE_ID||"en-IN-NeerjaExpressiveNeural"},WHISPER_STT:{URL:process.env.NEXT_PUBLIC_WHISPER_STT_URL||"https://dypstt.ccxai.uk"},OLLAMA:{URL:process.env.NEXT_PUBLIC_OLLAMA_URL||"https://dypai.ccxai.uk",MODEL:process.env.NEXT_PUBLIC_OLLAMA_MODEL||"gemma3:latest"}}},2348:(e,t,r)=>{r.d(t,{v:()=>n});class a{createLogEntry(e,t,r,a,n){return{timestamp:new Date().toISOString(),level:e,service:t,message:r,data:a,error:n}}addLog(e){this.logs.push(e),this.logs.length>this.maxLogs&&this.logs.shift();let t=`[${e.timestamp}] [${e.level.toUpperCase()}] [${e.service}] ${e.message}`;switch(e.level){case"debug":console.debug(t,e.data);break;case"info":console.info(t,e.data);break;case"warn":console.warn(t,e.data);break;case"error":console.error(t,e.error||e.data)}}debug(e,t,r){this.addLog(this.createLogEntry("debug",e,t,r))}info(e,t,r){this.addLog(this.createLogEntry("info",e,t,r))}warn(e,t,r){this.addLog(this.createLogEntry("warn",e,t,r))}error(e,t,r){this.addLog(this.createLogEntry("error",e,t,void 0,r))}getLogs(){return[...this.logs]}clearLogs(){this.logs=[]}constructor(){this.logs=[],this.maxLogs=1e3}}let n=new a},7870:(e,t,r)=>{r.d(t,{d:()=>s});var a=r(9429),n=r(2348);class o{constructor(){this.baseUrl=a.E$.OLLAMA.URL,this.model=a.E$.OLLAMA.MODEL,n.v.info("OllamaLLMAdapter","Initialized Ollama LLM adapter",{baseUrl:this.baseUrl,model:this.model})}async generateResponse(e){n.v.debug("OllamaLLMAdapter","Starting LLM generation",{messageCount:e.length,model:this.model});try{let t=await fetch(`${this.baseUrl}/api/chat`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:this.model,messages:e,stream:!1})});if(!t.ok)throw Error(`Ollama responded with status: ${t.status}`);let r=await t.json(),a=r.message.content;return n.v.info("OllamaLLMAdapter","LLM generation completed",{responseLength:a.length,totalDuration:r.total_duration,evalCount:r.eval_count}),a}catch(e){throw n.v.error("OllamaLLMAdapter","LLM generation failed",e),e}}async *generateStreamingResponse(e){n.v.debug("OllamaLLMAdapter","Starting streaming LLM generation",{messageCount:e.length,model:this.model});try{let t=await fetch(`${this.baseUrl}/api/chat`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({model:this.model,messages:e,stream:!0})});if(!t.ok)throw Error(`Ollama responded with status: ${t.status}`);let r=t.body?.getReader();if(!r)throw Error("No response body reader available");let a=new TextDecoder,o="";try{for(;;){let{done:e,value:t}=await r.read();if(e)break;let s=(o+=a.decode(t,{stream:!0})).split("\n");for(let e of(o=s.pop()||"",s))if(e.trim())try{let t=JSON.parse(e);if(t.message?.content&&(yield t.message.content),t.done){n.v.info("OllamaLLMAdapter","Streaming LLM generation completed");return}}catch(t){n.v.warn("OllamaLLMAdapter","Failed to parse streaming response line",{line:e})}}}finally{r.releaseLock()}}catch(e){throw n.v.error("OllamaLLMAdapter","Streaming LLM generation failed",e),e}}async testConnection(){try{n.v.debug("OllamaLLMAdapter","Testing Ollama service connection");let e=await fetch(`${this.baseUrl}/api/tags`);if(!e.ok)return n.v.info("OllamaLLMAdapter","Ollama service health check",{status:"unhealthy",statusCode:e.status}),!1;{let t=await e.json(),r=t.models?.some(e=>e.name.includes(this.model.split(":")[0]));return n.v.info("OllamaLLMAdapter","Ollama service health check",{status:"healthy",modelAvailable:r,availableModels:t.models?.map(e=>e.name)||[]}),r}}catch(e){return n.v.error("OllamaLLMAdapter","Ollama service health check failed",e),!1}}async pullModel(){try{return n.v.info("OllamaLLMAdapter","Pulling model",{model:this.model}),(await fetch(`${this.baseUrl}/api/pull`,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({name:this.model})})).ok}catch(e){return n.v.error("OllamaLLMAdapter","Model pull failed",e),!1}}}let s=new o}};